{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import pylab as p\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesClassifier, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from sklearn import cross_validation\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import median_absolute_error, mean_squared_error, explained_variance_score, mean_absolute_error, r2_score\n",
    "from sklearn.cross_validation import ShuffleSplit, train_test_split\n",
    "import scipy\n",
    "import random\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "core_df = pd.read_csv('/Users/jostheim/workspace/kaggle/data/nfl/NFLData_2000-2012/CORE.csv')\n",
    "game_df = pd.read_csv('/Users/jostheim/workspace/kaggle/data/nfl/NFLData_2000-2012/GAMES.csv')\n",
    "player_df = pd.read_csv('/Users/jostheim/workspace/kaggle/data/nfl/NFLData_2000-2012/PLAYERS.csv', index_col=[0])\n",
    "team_df = pd.read_csv('/Users/jostheim/workspace/kaggle/data/nfl/NFLData_2000-2012/TEAM.csv', index_col=[0])\n",
    "plays_df = pd.read_csv('/Users/jostheim/workspace/kaggle/data/nfl/NFLData_2000-2012/CORE.csv', index_col=[1])\n",
    "pass_df = pd.read_csv('/Users/jostheim/workspace/kaggle/data/nfl/NFLData_2000-2012/PASS.csv', index_col=[0])\n",
    "rush_df = pd.read_csv('/Users/jostheim/workspace/kaggle/data/nfl/NFLData_2000-2012/RUSH.csv', index_col=[0])\n",
    "pass_df = pass_df.join(plays_df)\n",
    "rush_df = rush_df.join(plays_df)\n",
    "conv_df = pd.read_csv('/Users/jostheim/workspace/kaggle/data/nfl/NFLData_2000-2012/CONVS.csv', index_col=[0])\n",
    "conv_df = conv_df.join(plays_df['GID'])\n",
    "kickoff_df = pd.read_csv('/Users/jostheim/workspace/kaggle/data/nfl/NFLData_2000-2012/KICKOFFS.csv', index_col=[0])\n",
    "kickoff_df = kickoff_df.join(plays_df)\n",
    "\n",
    "punt_df = pd.read_csv('/Users/jostheim/workspace/kaggle/data/nfl/NFLData_2000-2012/PUNTS.csv', index_col=[0])\n",
    "punt_df = punt_df.join(plays_df)\n",
    "tackle_df = pd.read_csv('/Users/jostheim/workspace/kaggle/data/nfl/NFLData_2000-2012/TACKLES.csv', index_col=[0])\n",
    "intercept_df = pd.read_csv('/Users/jostheim/workspace/kaggle/data/nfl/NFLData_2000-2012/INTS.csv', index_col=[0])\n",
    "fumble_df = pd.read_csv('/Users/jostheim/workspace/kaggle/data/nfl/NFLData_2000-2012/FUMBLES.csv', index_col=[0])\n",
    "tackle_df = tackle_df.join(plays_df)\n",
    "intercept_df = intercept_df.join(plays_df)\n",
    "fumble_df = fumble_df.join(plays_df)\n",
    "\n",
    "\n",
    "\n",
    "#win_orig_df = win_orig_df.join(game_df)\n",
    "offense_df = pd.read_csv('/Users/jostheim/workspace/kaggle/data/nfl/NFLData_2000-2012/OFFENSE.csv', index_col=[2])\n",
    "offense_df['PLAYER'] = offense_df.index\n",
    "defense_df = pd.read_csv('/Users/jostheim/workspace/kaggle/data/nfl/NFLData_2000-2012/DEFENSE.csv', index_col=[2])\n",
    "defense_df['PLAYER'] = defense_df.index\n",
    "players_df = pd.read_csv('/Users/jostheim/workspace/kaggle/data/nfl/NFLData_2000-2012/PLAYERS.csv', index_col=[0])\n",
    "offense_df = offense_df.join(players_df['POS1'])\n",
    "offense_df = offense_df.rename(columns={'POS1':'POS'})\n",
    "defense_df = defense_df.join(players_df['POS1'])\n",
    "defense_df = defense_df.rename(columns={'POS1':'POS'})\n",
    "\n",
    "players_df['player_id'] = players_df.index\n",
    "# offense_df = offense_df.join(players_df)\n",
    "# defense_df = defense_df.join(players_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pass_groups = pass_df.groupby(['GID', 'PSR']) \n",
    "snp_list = []\n",
    "for name, group in pass_groups:\n",
    "    snp_list.append({\"GID\":name[0], \"PLAYER\":name[1], \"PASSER_SNP\":len(group)})\n",
    "snp_df = pd.DataFrame(snp_list)\n",
    "snp_df = snp_df.fillna(0)\n",
    "offense_df = pd.merge(offense_df, snp_df, how='left', on=['GID', 'PLAYER'])\n",
    "\n",
    "pass_groups = pass_df.groupby(['GID', 'TRG']) \n",
    "snp_list = []\n",
    "for name, group in pass_groups:\n",
    "    snp_list.append({\"GID\":name[0], \"PLAYER\":name[1], \"TRG_SNP\":len(group)})\n",
    "snp_df = pd.DataFrame(snp_list)\n",
    "snp_df = snp_df.fillna(0)\n",
    "offense_df = pd.merge(offense_df, snp_df, how='left', on=['GID', 'PLAYER'])\n",
    "\n",
    "rush_groups = rush_df.groupby(['GID', 'BC']) \n",
    "snp_list = []\n",
    "for name, group in rush_groups:\n",
    "    snp_list.append({\"GID\":name[0], \"PLAYER\":name[1], \"BC_SNP\":len(group)})\n",
    "snp_df = pd.DataFrame(snp_list)\n",
    "snp_df = snp_df.fillna(0)\n",
    "offense_df = pd.merge(offense_df, snp_df, how='left', on=['GID', 'PLAYER'])\n",
    "\n",
    "fumble_groups = fumble_df.groupby(['GID', 'FRCV'])\n",
    "fumble_list = []\n",
    "for name, group in fumble_groups:\n",
    "    fumble_list.append({\"GID\":name[0], \"PLAYER\":name[1], \"FRCV\":len(group)})\n",
    "fumble_rcv_df = pd.DataFrame(fumble_list)\n",
    "fumble_rcv_df = fumble_rcv_df.fillna(0)\n",
    "offense_df = pd.merge(offense_df, fumble_rcv_df, how='left', on=['GID', 'PLAYER'])\n",
    "\n",
    "run_conv_groups = conv_df[conv_df['CONV'] == 'Y'].groupby(['GID', 'BC'])\n",
    "run_conv_list = []\n",
    "for name, group in run_conv_groups:\n",
    "    run_conv_list.append({\"GID\":name[0], \"PLAYER\":name[1], \"2PTCONV_BC\":len(group)})\n",
    "run_conv_df = pd.DataFrame(run_conv_list)\n",
    "run_conv_df = run_conv_df.fillna(0)\n",
    "offense_df = pd.merge(offense_df, run_conv_df, how='left', on=['GID', 'PLAYER'])\n",
    "\n",
    "\n",
    "passer_conv_groups = conv_df[conv_df['CONV'] == 'Y'].groupby(['GID', 'PSR'])\n",
    "passer_conv_list = []\n",
    "for name, group in passer_conv_groups:\n",
    "    passer_conv_list.append({\"GID\":name[0], \"PLAYER\":name[1], \"2PTCONV_PSR\":len(group)})\n",
    "passer_conv_df = pd.DataFrame(passer_conv_list)\n",
    "passer_conv_df = passer_conv_df.fillna(0)\n",
    "offense_df = pd.merge(offense_df, passer_conv_df, how='left', on=['GID', 'PLAYER'])\n",
    "\n",
    "passertrg_conv_groups = conv_df[conv_df['CONV'] == 'Y'].groupby(['GID', 'TRG'])\n",
    "passertrg_conv_list = []\n",
    "for name, group in passertrg_conv_groups:\n",
    "    passertrg_conv_list.append({\"GID\":name[0], \"PLAYER\":name[1], \"2PTCONV_TRG\":len(group)})\n",
    "passertrg_conv_df = pd.DataFrame(passertrg_conv_list)\n",
    "passertrg_conv_df = passertrg_conv_df.fillna(0)\n",
    "offense_df = pd.merge(offense_df, passertrg_conv_df, how='left', on=['GID', 'PLAYER'])\n",
    "\n",
    "punt_groups = punt_df[punt_df['PTSO'] == 6].groupby(['GID', 'PR'])\n",
    "punt_list = []\n",
    "for name, group in punt_groups:\n",
    "    punt_list.append({\"GID\":name[0], \"PLAYER\":name[1], \"PUNT_TDRET\":len(group)})\n",
    "punt_df = pd.DataFrame(punt_list)\n",
    "punt_df = punt_df.fillna(0)\n",
    "offense_df = pd.merge(offense_df, punt_df, how='left', on=['GID', 'PLAYER'])\n",
    "\n",
    "kickoff_groups = kickoff_df[kickoff_df['PTSO'] == 6].groupby(['GID', 'KR'])\n",
    "kickoff_list = []\n",
    "for name, group in kickoff_groups:\n",
    "    kickoff_list.append({\"GID\":name[0], \"PLAYER\":name[1], \"KICKOFF_TDRET\":len(group)})\n",
    "kickoff_df = pd.DataFrame(kickoff_list)\n",
    "kickoff_df = kickoff_df.fillna(0)\n",
    "offense_df = pd.merge(offense_df, kickoff_df, how='left', on=['GID', 'PLAYER'])\n",
    "\n",
    "offense_df['TDRET'] = offense_df['PUNT_TDRET'] + offense_df['KICKOFF_TDRET']\n",
    "\n",
    "offense_df['2PTCONV'] = offense_df['2PTCONV_BC'] + offense_df['2PTCONV_PSR'] + offense_df['2PTCONV_TRG']\n",
    "\n",
    "offense_df['SNP'] = offense_df['BC_SNP'] + offense_df['TRG_SNP'] +offense_df['PASSER_SNP']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tackle_groups = tackle_df.groupby(['GID', 'TCK']) \n",
    "snp_list = []\n",
    "for name, group in tackle_groups:\n",
    "    snp_list.append({\"GID\":name[0], \"PLAYER\":name[1], \"TACKLE_SNP\":len(group)})\n",
    "snp_df = pd.DataFrame(snp_list)\n",
    "snp_df = snp_df.fillna(0)\n",
    "defense_df = pd.merge(defense_df, snp_df, how='left', on=['GID', 'PLAYER'])\n",
    "\n",
    "intercept_groups = intercept_df.groupby(['GID', 'INT']) \n",
    "snp_list = []\n",
    "for name, group in intercept_groups:\n",
    "    snp_list.append({\"GID\":name[0], \"PLAYER\":name[1], \"INTERCEPT_SNP\":len(group)})\n",
    "snp_df = pd.DataFrame(snp_list)\n",
    "snp_df = snp_df.fillna(0)\n",
    "defense_df = pd.merge(defense_df, snp_df, how='left', on=['GID', 'PLAYER'])\n",
    "\n",
    "fumble_groups = fumble_df.groupby(['GID', 'FRCV']) \n",
    "snp_list = []\n",
    "for name, group in fumble_groups:\n",
    "    snp_list.append({\"GID\":name[0], \"PLAYER\":name[1], \"FUMBLE_SNP\":len(group)})\n",
    "snp_df = pd.DataFrame(snp_list)\n",
    "snp_df = snp_df.fillna(0)\n",
    "defense_df = pd.merge(defense_df, snp_df, how='left', on=['GID', 'PLAYER'])\n",
    "\n",
    "defense_df['SNP'] = defense_df['TACKLE_SNP'] + defense_df['INTERCEPT_SNP'] + defense_df['FUMBLE_SNP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draft_kings_score(row):\n",
    "    score = (row['TDP']*4.0) + (row['PY']*0.04) + (3 * (1.0 if row['PY'] > 300 else 0.0)) \n",
    "    score += (-1*row['INT']) + (0.1*row['RY']) + (6.0*row['TDR']) \n",
    "    score += (3*(1.0 if row['RY'] > 100 else 0.0)) + (0.1 * row['RECY']) + (1 * row['REC']) + (6 * row['TDRE'])\n",
    "    score += (3 *(1.0 if row['RECY'] > 100 else 0.0))\n",
    "#     score += (6 * row['TDRET']) + (-1 * row['FUML']) + (6 * row['FRCV']) + (2 * row['2PTCONV']) \n",
    "    return score\n",
    "\n",
    "offense_df['GID_tmp'] = offense_df['GID']\n",
    "offense_df['TEAM_tmp'] = offense_df['TEAM']\n",
    "offense_df = offense_df.set_index(['GID', 'TEAM'])\n",
    "offense_df['GID'] = offense_df['GID_tmp']\n",
    "offense_df['TEAM'] = offense_df['TEAM_tmp']\n",
    "\n",
    "offense_df = offense_df.fillna(0.0)\n",
    "\n",
    "offense_df['dk_fpts'] = offense_df.apply(lambda row:  draft_kings_score(row), axis=1)\n",
    "\n",
    "\n",
    "defense_df['GID_tmp'] = defense_df['GID']\n",
    "defense_df['TEAM_tmp'] = defense_df['TEAM']\n",
    "defense_df = defense_df.set_index(['GID', 'TEAM'])\n",
    "defense_df['GID'] = defense_df['GID_tmp']\n",
    "defense_df['TEAM'] = defense_df['TEAM_tmp']\n",
    "\n",
    "del offense_df['TEAM_tmp']\n",
    "del offense_df['GID_tmp']\n",
    "del defense_df['TEAM_tmp']\n",
    "del defense_df['GID_tmp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "offense_df['dk_fpts'].plot(kind=\"hist\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "player_id_map = {}\n",
    "for i, player_id in enumerate(player_df.index):\n",
    "    player_id_map[player_id] = i\n",
    "print player_id_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ignore_columns = ['PLAYER', 'GID', 'TID', 'TNAME', 'POS', 'UID', 'TEAM']\n",
    "categorical_to_binary_columns = ['V', 'H','STAD', 'WDIR', 'COND', 'SURF', 'TEAM', 'DAY']\n",
    "convert_to_float_columns = ['HUMD', 'WSPD']\n",
    "non_aggregable_colums = ['SEAS', 'YEAR', 'GAME']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_game_features(index, game, my_team):\n",
    "    feature = {}\n",
    "    #setup the features from the game data (weather, point spread and stuff)\n",
    "    if my_team == game['V'].values[0]:\n",
    "        feature['is_visitor'] = 1.0\n",
    "    else:\n",
    "        feature['is_visitor'] = 0.0\n",
    "    \n",
    "    for key, val in game.iteritems():\n",
    "        if key in ignore_columns:\n",
    "            continue\n",
    "        if key in categorical_to_binary_columns:\n",
    "            if val.values[0] != \"\\N\":\n",
    "                feature['IS_{0}_{1}'.format(index, val.values[0])] = 1.0\n",
    "        else:\n",
    "            if str(val.dtype) == \"object\":\n",
    "                if key in convert_to_float_columns:\n",
    "                    if str.isdigit(val.values[0].strip()):\n",
    "                        feature['{0}_{1}'.format(index, key)] = float(val.values[0])\n",
    "                    else:\n",
    "                        feature['{0}_{1}'.format(index, key)]  = 0.0\n",
    "                else:\n",
    "                    feature['{0}_{1}'.format(index, key)] = val.values[0]\n",
    "            else:\n",
    "                feature['{0}_{1}'.format(index, key)] = val.values[0]\n",
    "    return feature\n",
    "\n",
    "def get_team_game_features(index, team_game_data, game, players_team):\n",
    "    feature = {}\n",
    "    for team_game_row in team_game_data.iterrows():\n",
    "        this_player_team = False\n",
    "        # setup which team for this game is this_players team\n",
    "        if players_team == team_game_row[1]['TNAME']:\n",
    "            this_player_team = True\n",
    "        if not this_player_team:\n",
    "            continue\n",
    "        # setup the features from the teams participating in the game\n",
    "        for key, val in team_game_row[1].iteritems():\n",
    "            if key in ignore_columns:\n",
    "                continue\n",
    "            if key in categorical_to_binary_columns:\n",
    "                feature['IS_{0}_{1}_{2}'.format(index, val.values[0], 'my' if this_player_team else 'opp')] = 1.0\n",
    "            else:\n",
    "                feature['{0}_{1}_{2}'.format(index, 'my' if this_player_team else 'opp', key)] = val\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features_for_player(index, offesne_player_row):\n",
    "    feature = {}\n",
    "    for key, val in offesne_player_row.iteritems():\n",
    "        if key in ignore_columns:\n",
    "            continue\n",
    "        if key in categorical_to_binary_columns:\n",
    "            feature[\"IS_{0}_{1}\".format(val, index)] = 1.0\n",
    "        else:\n",
    "            feature[\"{0}_{1}\".format(key, index)] = val\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_career_features_for_player(stats_df, player_id, game_id):\n",
    "    feature = {}\n",
    "    all_player = stats_df[(stats_df['PLAYER'] == player_id) & (stats_df['GID'] < game_id)]\n",
    "#     all_player = stats_df[(stats_df['PLAYER'] == player_id)]\n",
    "    for i, column in enumerate(all_player.columns):\n",
    "        col_name = all_player.columns[i]\n",
    "        if col_name in ignore_columns or str(all_player.dtypes[i]) == \"object\":\n",
    "            continue\n",
    "        feature[\"career_{0}_sum\".format(col_name)] = all_player[column].sum()\n",
    "        feature[\"career_{0}_mean\".format(col_name)] = all_player[column].mean()\n",
    "        feature[\"career_{0}_std\".format(col_name)] = all_player[column].std()\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_moving_mean_features(index, moving_mean):\n",
    "    feature = {}\n",
    "    for i, col_name in enumerate(moving_mean.columns):\n",
    "        if col_name in ignore_columns:\n",
    "            continue\n",
    "        if col_name not in categorical_to_binary_columns:\n",
    "            feature[\"moving_average_{0}_{1}_sum\".format(index, col_name)] = moving_mean[col_name].sum()\n",
    "            feature[\"moving_average_{0}_{1}_mean\".format(index, col_name)] = moving_mean[col_name].mean()\n",
    "            feature[\"moving_average_{0}_{1}_std\".format(index, col_name)] = moving_mean[col_name].std()\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_previous_game_features(index, game_id, team):\n",
    "    feature = {}\n",
    "    games = game_df[game_df['GID'] < game_id]\n",
    "    games = games.sort(['GID'], ascending=[0])\n",
    "    games['winner'] = games.apply(lambda: 1.0 if (games['V'] == team and games['PTSV'] > games['PTSH']) or (games['H'] == team and games['PTSH'] > games['PTSV']) else 0.0) \n",
    "\n",
    "def get_current_game_features(index, game_id):\n",
    "    feature = {}\n",
    "    game = game_df[game_df['GID'] == game_id]\n",
    "    feature['{0}_OU'.format(index)] = game['OU'].values[0]\n",
    "    feature['{0}_SPRV'.format(index)] = game['SPRV'].values[0]\n",
    "    feature['{0}_WEEK'.format(index)] = game['WEEK'].values[0]\n",
    "    feature['{0}_SEAS'.format(index)] = game['SEAS'].values[0]\n",
    "    return feature\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_okay_cols(df, ignore_categorical=True): \n",
    "    okay_cols = []\n",
    "    for col in df.columns:\n",
    "        if (col not in ignore_columns and col not in non_aggregable_colums and (not ignore_categorical or col not in categorical_to_binary_columns)):\n",
    "            okay_cols.append(col)\n",
    "    return okay_cols+[]\n",
    "\n",
    "def get_flattened_columns(prefix, pivot_table):    \n",
    "    cols = []\n",
    "    col_dict = {}\n",
    "    for i, (col, gid) in enumerate(pivot_table.columns.tolist()):\n",
    "        if gid not in col_dict:\n",
    "            col_dict[gid] = str(i)\n",
    "        cols.append(prefix+col_dict[gid]+\"_\"+col)\n",
    "    return cols\n",
    "\n",
    "\n",
    "def get_historical_features_for_player(j, stats_df, player_id, game_id, my_team, opp_team, position):\n",
    "    feature = get_current_game_features(j, game_id)\n",
    "    end = 10\n",
    "    target = None\n",
    "    # all games < than the game in question\n",
    "    player_games = stats_df[(stats_df['PLAYER'] == player_id) & (stats_df['GID'] <= game_id)]\n",
    "    # resort the plays in game_id order\n",
    "    orig_player_games = player_games.sort(['GID'], ascending=[0])\n",
    "    if len(orig_player_games) > 48:\n",
    "        # target is the game_id games value of Fantasy points\n",
    "        target = orig_player_games['dk_fpts'].values[0]\n",
    "        # put in the career features\n",
    "        feature['player_id'] = player_id_map[player_id]\n",
    "        feature['is_{0}'.format(position)] = True\n",
    "        feature.update(get_career_features_for_player(stats_df, player_id, game_id))\n",
    "        # we want to use all the game data after the game_id\n",
    "        player_games = orig_player_games[1:end]\n",
    "        okay_cols = get_okay_cols(player_games, False)\n",
    "        okay_cols += ['PLAYER', 'GID', 'GAME', 'SEAS', 'YEAR']\n",
    "        player_games = player_games[okay_cols]\n",
    "        player_games_pivot = player_games.pivot(index='PLAYER', columns='GID')\n",
    "        cols = get_flattened_columns(\"\", player_games_pivot)\n",
    "        player_games_pivot.columns = cols\n",
    "        \n",
    "\n",
    "        okay_cols = get_okay_cols(player_games)\n",
    "        # expanding mean for games 1 - 4 after game_id\n",
    "        expanding_mean = pd.expanding_mean(player_games[okay_cols][1:end], min_periods=1)\n",
    "        expanding_mean['PLAYER'] = player_games['PLAYER']\n",
    "        expanding_mean['GID'] = player_games['GID']\n",
    "        expanding_mean_pivot = expanding_mean.pivot(index='PLAYER', columns='GID')\n",
    "        cols = get_flattened_columns(\"expanding_mean_\", expanding_mean_pivot)\n",
    "        expanding_mean_pivot.columns = cols\n",
    "        player_games_pivot = player_games_pivot.join(expanding_mean_pivot)\n",
    "        \n",
    "        # expanding std for games 1 - 4 after game_id\n",
    "        expanding_mean = pd.expanding_std(player_games[okay_cols][1:end], min_periods=1)\n",
    "        expanding_mean['PLAYER'] = player_games['PLAYER']\n",
    "        expanding_mean['GID'] = player_games['GID']\n",
    "        expanding_mean_pivot = expanding_mean.pivot(index='PLAYER', columns='GID')\n",
    "        cols = get_flattened_columns(\"expanding_std_\", expanding_mean_pivot)\n",
    "        expanding_mean_pivot.columns = cols\n",
    "        player_games_pivot = player_games_pivot.join(expanding_mean_pivot)\n",
    "        \n",
    "        # expanding sum for games 1 - 4 after game_id\n",
    "        expanding_mean = pd.expanding_sum(player_games[okay_cols][1:end], min_periods=1)\n",
    "        expanding_mean['PLAYER'] = player_games['PLAYER']\n",
    "        expanding_mean['GID'] = player_games['GID']\n",
    "\n",
    "        expanding_mean_pivot = expanding_mean.pivot(index='PLAYER', columns='GID')\n",
    "        cols = get_flattened_columns(\"expanding_sum_\", expanding_mean_pivot)\n",
    "        expanding_mean_pivot.columns = cols        \n",
    "        player_games_pivot = player_games_pivot.join(expanding_mean_pivot)\n",
    "        \n",
    "#         expanding_mean = pd.expanding_median(player_games[okay_cols][1:end], min_periods=1)\n",
    "#         expanding_mean['PLAYER'] = player_games['PLAYER']\n",
    "#         expanding_mean['GID'] = player_games['GID']\n",
    "#         expanding_mean_pivot = expanding_mean.pivot(index='PLAYER', columns='GID')\n",
    "#         cols = get_flattened_columns(\"expanding_median_\", expanding_mean_pivot)\n",
    "#         expanding_mean_pivot.columns = cols        \n",
    "#         player_games_pivot = player_games_pivot.join(expanding_mean_pivot)\n",
    " \n",
    "        for i, (index, row) in enumerate(player_games_pivot.iterrows()):\n",
    "            feature = {}\n",
    "            for key, val in row.iteritems():\n",
    "                if key in ignore_columns:\n",
    "                    continue\n",
    "                if key in categorical_to_binary_columns:\n",
    "                    feature[\"IS_{0}_{1}\".format(val, i)] = true\n",
    "                else:\n",
    "                    feature[\"{0}_{1}\".format(key, i)] = val\n",
    "#         print player_games_pivot.columns\n",
    "        \n",
    "#         for i,(index, row) in enumerate(player_plays.iterrows()):\n",
    "#             player_id = row['PLAYER']\n",
    "#             # target is this games fantasy points\n",
    "            \n",
    "#             pos = row['POS']\n",
    "#             # features are all the older games not including this one [i:] historical data\n",
    "#             # this means there is a feature for every game for each player\n",
    "#             moving_mean = pd.DataFrame(columns=player_plays.columns)\n",
    "#             for k, (index, player_row) in enumerate(player_plays[i+1:(i+5)].iterrows()):\n",
    "#                 game_id = player_row['GID']\n",
    "#                 # this will be the 2 teams that played\n",
    "#                 team_game_data = team_df[team_df['GID'] == game_id]\n",
    "#                 # this is basic info on the game, who is home and visitor\n",
    "#                 game = game_df[game_df['GID'] == game_id]\n",
    "# #                 feature.update(get_game_features(k, game, my_team))\n",
    "# #                 feature.update(get_team_game_features(k, team_game_data, game, my_team))\n",
    "#                 # setup the features for the player\n",
    "#                 feature.update(get_features_for_player(k, player_row))\n",
    "#                 moving_mean.loc[k] = player_row\n",
    "#                 feature.update(get_moving_mean_features(k, moving_mean))\n",
    "    return feature, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "def get_features_for_game(game_id, team, opp_team):\n",
    "    game_features = []\n",
    "#     print game_id, team, opp_team\n",
    "#     start = datetime.datetime.now()\n",
    "    offense_game_players = offense_df.ix[game_id].ix[team]\n",
    "#     print (datetime.datetime.now()-start).total_seconds()   \n",
    "#     offense_game_players = offense_df[(offense_df['GID'] == game_id) & (offense_df['TEAM'] == team)]\n",
    "    defense_game_players = defense_df.ix[game_id].ix[opp_team]\n",
    "#     defense_game_players = defense_df[(defense_df['GID'] == game_id) & (defense_df['TEAM'] == opp_team)]\n",
    "\n",
    "    print \"game_id:\", game_id, \"num_players:\", len(offense_game_players), len(defense_game_players)\n",
    "    # so everything is ordered the same, order by position and then by snaps descending, so the\n",
    "    # position with the most snaps is always first\n",
    "    offense_game_players = offense_game_players.sort(['POS', 'SNP'], ascending=[1, 0])\n",
    "    defense_game_players = defense_game_players.sort(['POS', 'SNP'], ascending=[1, 0])\n",
    "    offense_game_players_features = {}\n",
    "    defense_game_players_features = {}\n",
    "\n",
    "    # offense players\n",
    "#     start = datetime.datetime.now()\n",
    "    for j, (index, current_player) in enumerate(offense_game_players.iterrows()):\n",
    "        current_player_id = current_player['PLAYER']\n",
    "        # we go through the \"team\" players as offense\n",
    "        historical_features, target = get_historical_features_for_player(j, offense_df, current_player_id, game_id, team, opp_team, current_player['POS'])\n",
    "        offense_game_players_features[current_player_id] = (historical_features, target, current_player['POS'])\n",
    "#     print (datetime.datetime.now()-start).total_seconds()   \n",
    "\n",
    "    #defensive players\n",
    "#     start = datetime.datetime.now()\n",
    "#     for j, (index, current_player) in enumerate(defense_game_players.iterrows()):        \n",
    "#         current_player_id = current_player['PLAYER']\n",
    "#         # and the \"opp_team\" is the defense\n",
    "#         historical_features, target = get_historical_features_for_player(j, defense_df, current_player_id, game_id, opp_team, team, current_player['POS'])\n",
    "#         defense_game_players_features[current_player_id] = (historical_features, target, current_player['POS'])\n",
    "#     print (datetime.datetime.now()-start).total_seconds()   \n",
    "#     print \"finished getting features for players for game \", game_id \n",
    "    start = datetime.datetime.now()\n",
    "    for k, (player_id_focus, (features_focus, target, pos_focus)) in enumerate(offense_game_players_features.iteritems()):\n",
    "        feature = {'target':target}\n",
    "        feature.update(get_current_game_features(\"current\", game_id))\n",
    "        for j, (player_id, (features, target, pos)) in enumerate(offense_game_players_features.iteritems()):\n",
    "            prefix = \"off_{0}_{1}\".format(pos, j)\n",
    "            # if we are working on the current player as the focus then assign him the current tag\n",
    "            if player_id_focus == player_id:\n",
    "                prefix = \"off_current\"\n",
    "#             else:\n",
    "#                 continue\n",
    "            for i, (key, val) in enumerate(features.iteritems()):\n",
    "                feature['{0}_{1}'.format(prefix, key)] = val\n",
    "#         for j, (player_id, (features, target, pos)) in enumerate(defense_game_players_features.iteritems()):\n",
    "#             prefix = \"def_{0}_{1}\".format(pos, j)\n",
    "#             for i, (key, val) in enumerate(features.iteritems()):\n",
    "#                 feature['{0}_{1}'.format(prefix, key)] = val\n",
    "\n",
    "        game_features.append(feature)\n",
    "#     print (datetime.datetime.now()-start).total_seconds()   \n",
    "\n",
    "    return game_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_features_for_game_proxy(args):\n",
    "    game_id, team, opp_team, game_count = args\n",
    "    results = []\n",
    "    try:\n",
    "        results = get_features_for_game(game_id, team, opp_team)\n",
    "    except Exception as e:\n",
    "        print \"exception\",e\n",
    "#     if game_count%10 == 0:\n",
    "#         print \"finished up to \", game_id\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_count = len(game_df.index)\n",
    "all_features = []\n",
    "game_df = game_df.sort(['GID'], ascending=[0])\n",
    "cpu_count = 7\n",
    "pool = Pool(processes=cpu_count)\n",
    "pool_queue = []\n",
    "for game_count, (game_index, game) in enumerate(game_df.iterrows()):\n",
    "    game_id = game['GID']\n",
    "    teams = [game['H'], game['V']]\n",
    "    for team in teams:\n",
    "        opp_team = teams[0]\n",
    "        if team == teams[0]:\n",
    "            opp_team = teams[1]\n",
    "        pool_queue.append([game_id, team, opp_team, game_count])\n",
    "#         print get_features_for_game(game_id, team, opp_team)        \n",
    "#         all_features += get_features_for_game(game_id, team, opp_team)\n",
    "#         break\n",
    "#     break\n",
    "    if game_count > 2000:\n",
    "        break\n",
    "results = pool.map(get_features_for_game_proxy, pool_queue, 1)\n",
    "for result in results:\n",
    "    all_features += result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_df = pd.DataFrame(all_features)\n",
    "features_df = features_df.fillna(0.0)\n",
    "# print features_df\n",
    "for i, col in enumerate(features_df.columns):\n",
    "    print features_df.columns[i], features_df.dtypes[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_df = features_df.fillna(0.0)\n",
    "if 'target' in features_df.columns:\n",
    "    targets = features_df['target']\n",
    "if 'target' in features_df.columns:\n",
    "    del features_df['target']\n",
    "x_train, x_test, y_train, y_test = train_test_split(features_df, targets, test_size=0.33, random_state=42)\n",
    "\n",
    "clf = GradientBoostingRegressor(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "\n",
    "cfr = ExtraTreesRegressor(\n",
    "    oob_score = True, bootstrap=True, verbose = 1, max_features = len(features_df.columns), n_estimators = 1000, min_samples_leaf = 1,\n",
    "    n_jobs=7,\n",
    "    random_state=0,\n",
    ")\n",
    "cfr.fit(x_train, y_train)\n",
    "clf.fit(x_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for target in targets.values:\n",
    "    print target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score = cfr.score(x_test, y_test)\n",
    "print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Features sorted by their score:\"\n",
    "print sorted(zip(map(lambda x: round(x, 4), cfr.feature_importances_), x_train.columns), \n",
    "             reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = cfr.predict(x_test)\n",
    "plt.scatter(y_test, predictions)\n",
    "plt.show()\n",
    "print \"mean_absolute_error\", mean_absolute_error(y_test, predictions)\n",
    "print \"mean_squared_error\", mean_squared_error(y_test, predictions)\n",
    "print \"explained_variance\", explained_variance_score(y_test, predictions)\n",
    "print \"median_absolute_error\", median_absolute_error(y_test, predictions)\n",
    "print \"r2_score\", r2_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9ae76e7cfa47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.scatter(y_test, (y_test-predictions))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
